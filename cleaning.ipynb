{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5738aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gliclass import GLiClassModel, ZeroShotClassificationPipeline\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d24ceb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 191 entries, 0 to 190\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   country                                       191 non-null    object \n",
      " 1   total_data_centers                            191 non-null    Int64  \n",
      " 2   hyperscale_data_centers                       191 non-null    Int64  \n",
      " 3   colocation_data_centers                       191 non-null    Int64  \n",
      " 4   floor_space_sqft_total                        184 non-null    Int64  \n",
      " 5   power_capacity_MW_total                       165 non-null    Int64  \n",
      " 6   average_renewable_energy_usage_percent        148 non-null    Float64\n",
      " 7   cloud_provider                                149 non-null    object \n",
      " 8   internet_penetration_percent                  190 non-null    Float64\n",
      " 9   avg_latency_to_global_hubs_ms                 145 non-null    Float64\n",
      " 10  number_of_fiber_connections                   140 non-null    Float64\n",
      " 11  growth_rate_of_data_centers_percent_per_year  172 non-null    Int64  \n",
      " 12  cooling_technologies_common                   190 non-null    object \n",
      " 13  regulatory_challenges_or_limits               191 non-null    object \n",
      "dtypes: Float64(4), Int64(6), object(4)\n",
      "memory usage: 22.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/datacenter_dataset.csv')\n",
    "\n",
    "cols = ['country', 'total_data_centers', 'hyperscale_data_centers',\n",
    "        'colocation_data_centers', 'floor_space_sqft_total',\n",
    "        'power_capacity_MW_total', 'average_renewable_energy_usage_percent', \n",
    "        'cloud_provider', 'internet_penetration_percent', \n",
    "        'avg_latency_to_global_hubs_ms',\n",
    "        'number_of_fiber_connections',\n",
    "        'growth_rate_of_data_centers_percent_per_year',\n",
    "        'cooling_technologies_common', 'regulatory_challenges_or_limits']\n",
    "int_cols = [\n",
    "    'total_data_centers', \n",
    "    'hyperscale_data_centers',\n",
    "    'colocation_data_centers', \n",
    "    'floor_space_sqft_total',\n",
    "    'power_capacity_MW_total',\n",
    "    'growth_rate_of_data_centers_percent_per_year'\n",
    "]\n",
    "float_cols = [\n",
    "    'average_renewable_energy_usage_percent',\n",
    "    'internet_penetration_percent', \n",
    "    'avg_latency_to_global_hubs_ms',\n",
    "    'number_of_fiber_connections',\n",
    "]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df[int_cols] = df[int_cols].replace(r'[~,+]', '', regex=True) \\\n",
    "    .replace(r'\\([^)]*\\)', '', regex=True) \\\n",
    "    .apply(lambda x: x.str.split('[-–—]').str[-1] if x.dtype == 'object' else x) \\\n",
    "    .replace(r'[^\\d]+', ' ', regex=True) \\\n",
    "    .apply(pd.to_numeric, errors='coerce') \\\n",
    "    .astype('Int64')\n",
    "    \n",
    "df[float_cols] = df[float_cols].replace(r'[~,+]', '', regex=True) \\\n",
    "    .replace(r'\\([^)]*\\)', '', regex=True) \\\n",
    "    .apply(lambda x: x.str.split('[-–—]').str[-1] if x.dtype == 'object' else x) \\\n",
    "    .replace(r'[^\\d.]+', ' ', regex=True) \\\n",
    "    .apply(pd.to_numeric, errors='coerce') \\\n",
    "    .astype('Float64')\n",
    "    \n",
    "df.info()\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdbacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "print(\"Loading model...\")\n",
    "model = GLiClassModel.from_pretrained(\"knowledgator/gliclass-modern-base-v2.0-init\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"knowledgator/gliclass-modern-base-v2.0-init\", add_prefix_space=True)\n",
    "\n",
    "# Initialize GLiClass zero-shot classification pipeline\n",
    "print(\"Loading classifier pipeline...\")\n",
    "classifier = ZeroShotClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    classification_type='multi-label',  # important for binary-style output\n",
    "    device='cuda:0'  # or 'cpu' if no GPU\n",
    ")\n",
    "\n",
    "# Define your alias map\n",
    "alias_map = {\n",
    "    \"GCP\": [\"GCP\", \"Google\", \"Google Cloud\"],\n",
    "    \"AWS\": [\"AWS\", \"Amazon\", \"Amazon Web Services\"],\n",
    "    \"Azure\": [\"Azure\", \"Microsoft\", \"Microsoft Azure\"],\n",
    "    \"Oracle\": [\"Oracle\"]\n",
    "}\n",
    "\n",
    "# Classification function with logging\n",
    "def classify_with_aliases(text, alias_map, threshold=0.5):\n",
    "    print(f\"\\nProcessing text: {text}\")\n",
    "    \n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        print(\" - Skipped: Empty or invalid input\")\n",
    "        return {k: 0 for k in alias_map}\n",
    "    \n",
    "    # Flatten all aliases\n",
    "    all_aliases = [alias for aliases in alias_map.values() for alias in aliases]\n",
    "    print(f\" - Candidate labels: {all_aliases}\")\n",
    "    \n",
    "    # Run classification using GLiClass pipeline\n",
    "    result = classifier(text, all_aliases)\n",
    "    \n",
    "    # Initialize score dict\n",
    "    label_scores = {key: 0 for key in alias_map}\n",
    "    \n",
    "    # Assign scores based on best match per group\n",
    "    for alias, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        for key, aliases in alias_map.items():\n",
    "            if alias in aliases:\n",
    "                print(f\" - Matched alias: '{alias}' for key: '{key}' with score: {score:.4f}\")\n",
    "                label_scores[key] = max(label_scores[key], score)\n",
    "    \n",
    "    # Convert to binary using threshold\n",
    "    binary_result = {k: int(v > threshold) for k, v in label_scores.items()}\n",
    "    print(f\" - Final binary classification: {binary_result}\")\n",
    "    return binary_result\n",
    "\n",
    "binary_results = df['Cloud_provider'].apply(lambda x: classify_with_aliases(x, alias_map))\n",
    "binary_df = pd.DataFrame(binary_results.tolist())\n",
    "df = pd.concat([df, binary_df], axis=1)\n",
    "\n",
    "# Preview results\n",
    "df.head(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
