{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5738aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MOVE\\Portfolio\\ProjectDataCenter\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gliclass import GLiClassModel, ZeroShotClassificationPipeline\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24ceb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 191 entries, 0 to 190\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   country                                       191 non-null    object \n",
      " 1   total_data_centers                            191 non-null    Int64  \n",
      " 2   hyperscale_data_centers                       191 non-null    Int64  \n",
      " 3   colocation_data_centers                       191 non-null    Int64  \n",
      " 4   floor_space_sqft_total                        184 non-null    Int64  \n",
      " 5   power_capacity_MW_total                       165 non-null    Int64  \n",
      " 6   average_renewable_energy_usage_percent        148 non-null    Float64\n",
      " 7   cloud_provider                                149 non-null    object \n",
      " 8   internet_penetration_percent                  190 non-null    Float64\n",
      " 9   avg_latency_to_global_hubs_ms                 145 non-null    Float64\n",
      " 10  number_of_fiber_connections                   140 non-null    Float64\n",
      " 11  growth_rate_of_data_centers_percent_per_year  172 non-null    Int64  \n",
      " 12  cooling_technologies_common                   190 non-null    object \n",
      " 13  regulatory_challenges_or_limits               191 non-null    object \n",
      "dtypes: Float64(4), Int64(6), object(4)\n",
      "memory usage: 22.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/datacenter_dataset.csv')\n",
    "\n",
    "cols = ['country', 'total_data_centers', 'hyperscale_data_centers',\n",
    "        'colocation_data_centers', 'floor_space_sqft_total',\n",
    "        'power_capacity_MW_total', 'average_renewable_energy_usage_percent', \n",
    "        'cloud_provider', 'internet_penetration_percent', \n",
    "        'avg_latency_to_global_hubs_ms',\n",
    "        'number_of_fiber_connections',\n",
    "        'growth_rate_of_data_centers_percent_per_year',\n",
    "        'cooling_technologies_common', 'regulatory_challenges_or_limits']\n",
    "int_cols = [\n",
    "    'total_data_centers', \n",
    "    'hyperscale_data_centers',\n",
    "    'colocation_data_centers', \n",
    "    'floor_space_sqft_total',\n",
    "    'power_capacity_MW_total',\n",
    "    'growth_rate_of_data_centers_percent_per_year'\n",
    "]\n",
    "float_cols = [\n",
    "    'average_renewable_energy_usage_percent',\n",
    "    'internet_penetration_percent', \n",
    "    'avg_latency_to_global_hubs_ms',\n",
    "    'number_of_fiber_connections',\n",
    "]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df[int_cols] = df[int_cols].replace(r'[~,+]', '', regex=True) \\\n",
    "    .replace(r'\\([^)]*\\)', '', regex=True) \\\n",
    "    .apply(lambda x: x.str.split('[-–—]').str[-1] if x.dtype == 'object' else x) \\\n",
    "    .replace(r'[^\\d]+', ' ', regex=True) \\\n",
    "    .apply(pd.to_numeric, errors='coerce') \\\n",
    "    .astype('Int64')\n",
    "    \n",
    "df[float_cols] = df[float_cols].replace(r'[~,+]', '', regex=True) \\\n",
    "    .replace(r'\\([^)]*\\)', '', regex=True) \\\n",
    "    .apply(lambda x: x.str.split('[-–—]').str[-1] if x.dtype == 'object' else x) \\\n",
    "    .replace(r'[^\\d.]+', ' ', regex=True) \\\n",
    "    .apply(pd.to_numeric, errors='coerce') \\\n",
    "    .astype('Float64')\n",
    "    \n",
    "df.info()\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdbacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MOVE\\Portfolio\\ProjectDataCenter\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--knowledgator--gliclass-modern-base-v2.0-init. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/82/29/8229e385665623441da3a4bda551c3e8a55ceab58f427f86ae524ab0566b1a1d/b19561d9e821f0349abb785f8c3cdc8c493f403e1380db0880f8ec7f34141a13?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1753254784&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MzI1NDc4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzgyLzI5LzgyMjllMzg1NjY1NjIzNDQxZGEzYTRiZGE1NTFjM2U4YTU1Y2VhYjU4ZjQyN2Y4NmFlNTI0YWIwNTY2YjFhMWQvYjE5NTYxZDllODIxZjAzNDlhYmI3ODVmOGMzY2RjOGM0OTNmNDAzZTEzODBkYjA4ODBmOGVjN2YzNDE0MWExMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=LyMsDMhE1w2IdRG7PzRp93Gj%7EjZcuVzSGaGoIx1FhpIPMfvrFmUax2%7Eij7o67hF008J-FMoiA1iL%7EK1R%7EBIpRr4h8rdhQdlyBe8Jy2L5tSoctqxQuZWP5xvS0kqyIg6IK1jJ%7EhvoM2OdZHsnsR0RO%7EEjJNcwznW7XUYhVRINk41u1WmN1ufHvbLd5Imm-8nwCZNBoPwF-GFaZcShMZsVFFsJKaRTuMCTkRE153Id-aFBWjlNuglGGl9BWaIcpuzsGJgFM3iB4fE5QzLUb9Ief172YramN6pDY4apY2HIVWo-UEMw0muX6lqA37h5ZHAJBM%7Er1GLrYQocqao9DHuGGg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "print(\"Loading model...\")\n",
    "model = GLiClassModel.from_pretrained(\"knowledgator/gliclass-modern-base-v2.0-init\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"knowledgator/gliclass-modern-base-v2.0-init\", add_prefix_space=True)\n",
    "\n",
    "# Initialize GLiClass zero-shot classification pipeline\n",
    "print(\"Loading classifier pipeline...\")\n",
    "classifier = ZeroShotClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    classification_type='multi-label',  # important for binary-style output\n",
    "    device='cuda:0'  # or 'cpu' if no GPU\n",
    ")\n",
    "\n",
    "# Define your alias map\n",
    "alias_map = {\n",
    "    \"GCP\": [\"GCP\", \"Google\", \"Google Cloud\"],\n",
    "    \"AWS\": [\"AWS\", \"Amazon\", \"Amazon Web Services\"],\n",
    "    \"Azure\": [\"Azure\", \"Microsoft\", \"Microsoft Azure\"],\n",
    "    \"Oracle\": [\"Oracle\"]\n",
    "}\n",
    "\n",
    "# Classification function with logging\n",
    "def classify_with_aliases(text, alias_map, threshold=0.5):\n",
    "    print(f\"\\nProcessing text: {text}\")\n",
    "    \n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        print(\" - Skipped: Empty or invalid input\")\n",
    "        return {k: 0 for k in alias_map}\n",
    "    \n",
    "    # Flatten all aliases\n",
    "    all_aliases = [alias for aliases in alias_map.values() for alias in aliases]\n",
    "    print(f\" - Candidate labels: {all_aliases}\")\n",
    "    \n",
    "    # Run classification using GLiClass pipeline\n",
    "    result = classifier(text, all_aliases)\n",
    "    \n",
    "    # Initialize score dict\n",
    "    label_scores = {key: 0 for key in alias_map}\n",
    "    \n",
    "    # Assign scores based on best match per group\n",
    "    for alias, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        for key, aliases in alias_map.items():\n",
    "            if alias in aliases:\n",
    "                print(f\" - Matched alias: '{alias}' for key: '{key}' with score: {score:.4f}\")\n",
    "                label_scores[key] = max(label_scores[key], score)\n",
    "    \n",
    "    # Convert to binary using threshold\n",
    "    binary_result = {k: int(v > threshold) for k, v in label_scores.items()}\n",
    "    print(f\" - Final binary classification: {binary_result}\")\n",
    "    return binary_result\n",
    "\n",
    "binary_results = df['Cloud_provider'].apply(lambda x: classify_with_aliases(x, alias_map))\n",
    "binary_df = pd.DataFrame(binary_results.tolist())\n",
    "df = pd.concat([df, binary_df], axis=1)\n",
    "\n",
    "# Preview results\n",
    "df.head(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
